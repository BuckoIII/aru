{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text mining workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workbook, we will be using data gathered from a community event in Austin, Texas hosted by the police to discuss racial profiling.\n",
    "\n",
    "All of the required packages and modules can be imported by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "      <th>Question</th>\n",
       "      <th>Group</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have been an Austin resident for 1.5 years w...</td>\n",
       "      <td>What was your motivation for attending this ev...</td>\n",
       "      <td>1</td>\n",
       "      <td>Motivations and Feelings</td>\n",
       "      <td>People expressed interest in this community di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Long term Austin resident and UT student</td>\n",
       "      <td>What was your motivation for attending this ev...</td>\n",
       "      <td>1</td>\n",
       "      <td>Motivations and Feelings</td>\n",
       "      <td>People expressed interest in this community di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>works for councilmember Delia Garza</td>\n",
       "      <td>What was your motivation for attending this ev...</td>\n",
       "      <td>1</td>\n",
       "      <td>Motivations and Feelings</td>\n",
       "      <td>People expressed interest in this community di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to learn and gain new perspective</td>\n",
       "      <td>What was your motivation for attending this ev...</td>\n",
       "      <td>3</td>\n",
       "      <td>Motivations and Feelings</td>\n",
       "      <td>People expressed interest in this community di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Social work experience, and to take info/exper...</td>\n",
       "      <td>What was your motivation for attending this ev...</td>\n",
       "      <td>5</td>\n",
       "      <td>Motivations and Feelings</td>\n",
       "      <td>People expressed interest in this community di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Response  \\\n",
       "0  I have been an Austin resident for 1.5 years w...   \n",
       "1           Long term Austin resident and UT student   \n",
       "2                works for councilmember Delia Garza   \n",
       "3                  to learn and gain new perspective   \n",
       "4  Social work experience, and to take info/exper...   \n",
       "\n",
       "                                            Question  Group  \\\n",
       "0  What was your motivation for attending this ev...      1   \n",
       "1  What was your motivation for attending this ev...      1   \n",
       "2  What was your motivation for attending this ev...      1   \n",
       "3  What was your motivation for attending this ev...      3   \n",
       "4  What was your motivation for attending this ev...      5   \n",
       "\n",
       "                      Topic                                              Theme  \n",
       "0  Motivations and Feelings  People expressed interest in this community di...  \n",
       "1  Motivations and Feelings  People expressed interest in this community di...  \n",
       "2  Motivations and Feelings  People expressed interest in this community di...  \n",
       "3  Motivations and Feelings  People expressed interest in this community di...  \n",
       "4  Motivations and Feelings  People expressed interest in this community di...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/policing.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Word Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code cell to assign the text to the variable `motivation_question`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "motivation_question = 'What was your motivation for attending this event?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1)** Assign to the variable `motivation`, a DataFrame containing entries in `df` where `Question` equals the `motivation_question` given above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "      <th>Question</th>\n",
       "      <th>Group</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have been an Austin resident for 1.5 years w...</td>\n",
       "      <td>What was your motivation for attending this ev...</td>\n",
       "      <td>1</td>\n",
       "      <td>Motivations and Feelings</td>\n",
       "      <td>People expressed interest in this community di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Long term Austin resident and UT student</td>\n",
       "      <td>What was your motivation for attending this ev...</td>\n",
       "      <td>1</td>\n",
       "      <td>Motivations and Feelings</td>\n",
       "      <td>People expressed interest in this community di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>works for councilmember Delia Garza</td>\n",
       "      <td>What was your motivation for attending this ev...</td>\n",
       "      <td>1</td>\n",
       "      <td>Motivations and Feelings</td>\n",
       "      <td>People expressed interest in this community di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to learn and gain new perspective</td>\n",
       "      <td>What was your motivation for attending this ev...</td>\n",
       "      <td>3</td>\n",
       "      <td>Motivations and Feelings</td>\n",
       "      <td>People expressed interest in this community di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Social work experience, and to take info/exper...</td>\n",
       "      <td>What was your motivation for attending this ev...</td>\n",
       "      <td>5</td>\n",
       "      <td>Motivations and Feelings</td>\n",
       "      <td>People expressed interest in this community di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Response  \\\n",
       "0  I have been an Austin resident for 1.5 years w...   \n",
       "1           Long term Austin resident and UT student   \n",
       "2                works for councilmember Delia Garza   \n",
       "3                  to learn and gain new perspective   \n",
       "4  Social work experience, and to take info/exper...   \n",
       "\n",
       "                                            Question  Group  \\\n",
       "0  What was your motivation for attending this ev...      1   \n",
       "1  What was your motivation for attending this ev...      1   \n",
       "2  What was your motivation for attending this ev...      1   \n",
       "3  What was your motivation for attending this ev...      3   \n",
       "4  What was your motivation for attending this ev...      5   \n",
       "\n",
       "                      Topic                                              Theme  \n",
       "0  Motivations and Feelings  People expressed interest in this community di...  \n",
       "1  Motivations and Feelings  People expressed interest in this community di...  \n",
       "2  Motivations and Feelings  People expressed interest in this community di...  \n",
       "3  Motivations and Feelings  People expressed interest in this community di...  \n",
       "4  Motivations and Feelings  People expressed interest in this community di...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add your code below\n",
    "# motivation = ...\n",
    "\n",
    "motivation = df[df['Question'] == motivation_question]\n",
    "motivation.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2)** Create a `list`, assigned to the variable `motivation_words`, which contains all of the words found in the `Response` column of the `motivation` DataFrame: \n",
    "\n",
    "- create an empty list `motivation_words`\n",
    "- using a `for` loop, iterate through each entry in `motivation['Response']` and use `word_tokenize()` to get the separate words (`tokens`)\n",
    "- add all `tokens` into `motivation_words` list using `.extend()` method\n",
    "- don't for now remove any duplicates or stop words from the list, or change the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'have',\n",
       " 'been',\n",
       " 'an',\n",
       " 'Austin',\n",
       " 'resident',\n",
       " 'for',\n",
       " '1.5',\n",
       " 'years',\n",
       " 'with',\n",
       " 'family',\n",
       " 'here',\n",
       " ';',\n",
       " 'family',\n",
       " 'is',\n",
       " 'racially',\n",
       " 'mixed',\n",
       " ',',\n",
       " 'my',\n",
       " 'son',\n",
       " 'is',\n",
       " 'stopped',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'in',\n",
       " 'Philadelphia',\n",
       " 'Long',\n",
       " 'term',\n",
       " 'Austin',\n",
       " 'resident',\n",
       " 'and',\n",
       " 'UT',\n",
       " 'student',\n",
       " 'works',\n",
       " 'for',\n",
       " 'councilmember',\n",
       " 'Delia',\n",
       " 'Garza',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'and',\n",
       " 'gain',\n",
       " 'new',\n",
       " 'perspective',\n",
       " 'Social',\n",
       " 'work',\n",
       " 'experience',\n",
       " ',',\n",
       " 'and',\n",
       " 'to',\n",
       " 'take',\n",
       " 'info/experience',\n",
       " 'back',\n",
       " 'to',\n",
       " 'their',\n",
       " 'commision',\n",
       " 'To',\n",
       " 'better',\n",
       " 'understand',\n",
       " 'Help',\n",
       " 'contribute',\n",
       " 'to',\n",
       " 'discussion',\n",
       " 'and',\n",
       " 'work',\n",
       " 'on',\n",
       " 'solutions',\n",
       " 'Self',\n",
       " 'education',\n",
       " 'Share',\n",
       " 'outcomes',\n",
       " 'Anti-racism',\n",
       " 'consulting',\n",
       " ',',\n",
       " 'power',\n",
       " 'dynamics',\n",
       " 'in',\n",
       " 'social',\n",
       " 'systems',\n",
       " 'Public',\n",
       " 'policy',\n",
       " 'researcher',\n",
       " 'and',\n",
       " 'grad',\n",
       " 'student',\n",
       " 'at',\n",
       " 'UT',\n",
       " ',',\n",
       " 'studies',\n",
       " 'community',\n",
       " 'and',\n",
       " 'police',\n",
       " 'relations',\n",
       " 'and',\n",
       " 'does',\n",
       " 'stuff',\n",
       " 'with',\n",
       " 'Equity',\n",
       " 'Office',\n",
       " 'Race',\n",
       " 'equity',\n",
       " 'journey',\n",
       " 'Curious',\n",
       " 'to',\n",
       " 'hear',\n",
       " 'community',\n",
       " 'input',\n",
       " 'APD',\n",
       " 'commander',\n",
       " 'over',\n",
       " '10',\n",
       " 'years',\n",
       " ';',\n",
       " 'opportunity',\n",
       " 'to',\n",
       " 'hear',\n",
       " 'from',\n",
       " 'community',\n",
       " 'and',\n",
       " 'achieve',\n",
       " 'city',\n",
       " 'goals',\n",
       " ';',\n",
       " 'lived',\n",
       " 'all',\n",
       " 'over',\n",
       " 'Austin',\n",
       " 'since',\n",
       " 'the',\n",
       " '1980s',\n",
       " 'and',\n",
       " 'saw',\n",
       " 'disparities',\n",
       " 'Community',\n",
       " 'engagement',\n",
       " 'Community',\n",
       " 'engagement',\n",
       " 'Affordable',\n",
       " 'housing',\n",
       " 'interests',\n",
       " 'for',\n",
       " 'low-income',\n",
       " 'people',\n",
       " 'of',\n",
       " 'color',\n",
       " 'Equity',\n",
       " 'office',\n",
       " 'Identify',\n",
       " 'issues',\n",
       " 'and',\n",
       " 'share',\n",
       " 'experience',\n",
       " 'with',\n",
       " 'Undoing',\n",
       " 'White',\n",
       " 'Supremacy',\n",
       " 'Austin',\n",
       " ',',\n",
       " 'solutions',\n",
       " 'for',\n",
       " 'accountability',\n",
       " 'and',\n",
       " 'transparency',\n",
       " 'Works',\n",
       " 'with',\n",
       " 'APD',\n",
       " 'and',\n",
       " 'has',\n",
       " '2',\n",
       " 'perspectives',\n",
       " ':',\n",
       " 'long',\n",
       " 'time',\n",
       " 'resident',\n",
       " 'and',\n",
       " 'police',\n",
       " 'officer',\n",
       " 'perspective',\n",
       " '.',\n",
       " 'Vested',\n",
       " 'interest',\n",
       " 'in',\n",
       " 'improving',\n",
       " 'accountability',\n",
       " 'Important',\n",
       " 'issues',\n",
       " 'Community',\n",
       " 'Liaison',\n",
       " ',',\n",
       " 'police',\n",
       " 'officer',\n",
       " 'experience',\n",
       " 'Learn',\n",
       " 'new',\n",
       " 'perspective',\n",
       " 'Local',\n",
       " 'issues',\n",
       " 'work',\n",
       " 'in',\n",
       " 'community',\n",
       " 'and',\n",
       " 'want',\n",
       " 'to',\n",
       " 'make',\n",
       " 'an',\n",
       " 'impact',\n",
       " 'in',\n",
       " 'Williamson',\n",
       " 'County',\n",
       " 'listen',\n",
       " ',',\n",
       " 'understand',\n",
       " ',',\n",
       " 'be',\n",
       " 'part',\n",
       " 'of',\n",
       " 'solutions',\n",
       " 'Impacted',\n",
       " ',',\n",
       " 'here',\n",
       " 'to',\n",
       " 'listen',\n",
       " 'and',\n",
       " 'learn',\n",
       " 'Be',\n",
       " 'part',\n",
       " 'of',\n",
       " 'conversation',\n",
       " 'Over',\n",
       " '10',\n",
       " 'years',\n",
       " 'working',\n",
       " 'to',\n",
       " 'hold',\n",
       " 'APD',\n",
       " 'accountable',\n",
       " 'Austin',\n",
       " 'Interfaith',\n",
       " 'member',\n",
       " 'and',\n",
       " 'organizer',\n",
       " 'Be',\n",
       " 'part',\n",
       " 'of',\n",
       " 'conversation',\n",
       " 'Important',\n",
       " 'conversation',\n",
       " 'Excited',\n",
       " 'about',\n",
       " 'seeing',\n",
       " 'tangible',\n",
       " 'recommendations',\n",
       " 'East',\n",
       " 'Austin',\n",
       " 'resident',\n",
       " 'for',\n",
       " '30+',\n",
       " 'years',\n",
       " 'and',\n",
       " 'witness',\n",
       " 'to',\n",
       " 'aggressive',\n",
       " 'policing',\n",
       " 'Personal',\n",
       " 'experience',\n",
       " 'of',\n",
       " 'neighbors',\n",
       " 'am',\n",
       " 'a',\n",
       " 'Black',\n",
       " 'person',\n",
       " 'living',\n",
       " 'in',\n",
       " 'Austin',\n",
       " 'experiencing',\n",
       " 'disparities',\n",
       " 'discussed',\n",
       " 'in',\n",
       " 'the',\n",
       " 'report',\n",
       " 'Personal',\n",
       " 'experience',\n",
       " 'with',\n",
       " 'racial',\n",
       " 'profiling',\n",
       " 'Neighborhood',\n",
       " 'has',\n",
       " 'been',\n",
       " 'historically',\n",
       " 'policed',\n",
       " 'Long-time',\n",
       " 'resident',\n",
       " 'of',\n",
       " 'East',\n",
       " 'and',\n",
       " 'South',\n",
       " 'Austin',\n",
       " ',',\n",
       " 'attorney',\n",
       " ',',\n",
       " 'concerned',\n",
       " 'about',\n",
       " 'the',\n",
       " 'data',\n",
       " 'and',\n",
       " 'thinks',\n",
       " 'it',\n",
       " 'refutes',\n",
       " 'racial',\n",
       " 'profiling',\n",
       " 'Disrespectful',\n",
       " 'feeling',\n",
       " 'from',\n",
       " 'police',\n",
       " 'Different',\n",
       " 'Experience',\n",
       " 'for',\n",
       " 'white',\n",
       " 'people',\n",
       " 'in',\n",
       " 'neighborhood',\n",
       " 'Works',\n",
       " 'in',\n",
       " 'immigration',\n",
       " 'and',\n",
       " 'this',\n",
       " 'hits',\n",
       " 'close',\n",
       " 'to',\n",
       " 'home',\n",
       " 'Concerns',\n",
       " 'for',\n",
       " 'impact',\n",
       " 'on',\n",
       " 'undocumented',\n",
       " 'people',\n",
       " 'Under',\n",
       " 'policing',\n",
       " 'for',\n",
       " 'White',\n",
       " 'people',\n",
       " 'No',\n",
       " 'confusion',\n",
       " 'about',\n",
       " 'accountability',\n",
       " 'Owning',\n",
       " 'up',\n",
       " 'to',\n",
       " 'the',\n",
       " 'disparity',\n",
       " 'Concerning',\n",
       " 'that',\n",
       " 'the',\n",
       " 'police',\n",
       " 'chief',\n",
       " 'thinks',\n",
       " 'it',\n",
       " 'is',\n",
       " 'better',\n",
       " 'What',\n",
       " 'are',\n",
       " 'the',\n",
       " 'police',\n",
       " 'going',\n",
       " 'to',\n",
       " 'do',\n",
       " 'about',\n",
       " 'recommendations',\n",
       " '?',\n",
       " 'Police',\n",
       " 'have',\n",
       " 'not',\n",
       " 'prepared',\n",
       " 'to',\n",
       " 'respond',\n",
       " 'to',\n",
       " 'the',\n",
       " 'report',\n",
       " 'Not',\n",
       " 'feeling',\n",
       " 'any',\n",
       " 'urgency',\n",
       " 'from',\n",
       " 'the',\n",
       " 'police',\n",
       " 'Bring',\n",
       " 'lived',\n",
       " 'experiences',\n",
       " 'to',\n",
       " 'the',\n",
       " 'conversation',\n",
       " 'for',\n",
       " 'solutions',\n",
       " 'and',\n",
       " 'moving',\n",
       " 'forward',\n",
       " 'Addressing',\n",
       " 'anti-blackness',\n",
       " 'Changing',\n",
       " 'the',\n",
       " 'frame/structure',\n",
       " '.',\n",
       " 'Having',\n",
       " 'a',\n",
       " 'parallel',\n",
       " 'approach',\n",
       " 'Social',\n",
       " 'determinants',\n",
       " 'of',\n",
       " 'health',\n",
       " 'Working',\n",
       " 'on',\n",
       " 'public',\n",
       " 'health',\n",
       " 'issues',\n",
       " 'with',\n",
       " 'students',\n",
       " 'Bring',\n",
       " 'healthcare',\n",
       " 'perspective']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add your code below\n",
    "# motivation_words = ...\n",
    "\n",
    "motivation_words = []\n",
    "\n",
    "for text in motivation['Response']:\n",
    "    words = word_tokenize(text)\n",
    "    motivation_words.extend(words)\n",
    "\n",
    "motivation_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign to the variable `top_5` a `list` of the five most common words in `motivation_words`:\n",
    "- use `nltk.freqdist` and the `.most_common()` method\n",
    "- extract the words from the resulting tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 21), ('to', 16), (',', 11), ('the', 10), ('for', 9)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqdist = nltk.FreqDist(motivation_words).most_common(5)\n",
    "freqdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'to', ',', 'the', 'for']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5 = [entry[0] for entry in freqdist]\n",
    "top_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Q3)** Create a new list of words, assigned to `motivation_clean`, based on `motivation_words` but with:\n",
    "\n",
    "- all English stopwords removed\n",
    "- all words in lower case\n",
    "- words containing only alphabetical characters\n",
    "\n",
    "\n",
    "*For the alhpabetical characters requirement, consider using the Python [.isalpha()](https://www.w3schools.com/python/ref_string_isalpha.asp) method.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austin',\n",
       " 'resident',\n",
       " 'years',\n",
       " 'family',\n",
       " 'family',\n",
       " 'racially',\n",
       " 'mixed',\n",
       " 'son',\n",
       " 'stopped',\n",
       " 'lot',\n",
       " 'philadelphia',\n",
       " 'long',\n",
       " 'term',\n",
       " 'austin',\n",
       " 'resident',\n",
       " 'ut',\n",
       " 'student',\n",
       " 'works',\n",
       " 'councilmember',\n",
       " 'delia',\n",
       " 'garza',\n",
       " 'learn',\n",
       " 'gain',\n",
       " 'new',\n",
       " 'perspective',\n",
       " 'social',\n",
       " 'work',\n",
       " 'experience',\n",
       " 'take',\n",
       " 'back',\n",
       " 'commision',\n",
       " 'better',\n",
       " 'understand',\n",
       " 'help',\n",
       " 'contribute',\n",
       " 'discussion',\n",
       " 'work',\n",
       " 'solutions',\n",
       " 'self',\n",
       " 'education',\n",
       " 'share',\n",
       " 'outcomes',\n",
       " 'consulting',\n",
       " 'power',\n",
       " 'dynamics',\n",
       " 'social',\n",
       " 'systems',\n",
       " 'public',\n",
       " 'policy',\n",
       " 'researcher',\n",
       " 'grad',\n",
       " 'student',\n",
       " 'ut',\n",
       " 'studies',\n",
       " 'community',\n",
       " 'police',\n",
       " 'relations',\n",
       " 'stuff',\n",
       " 'equity',\n",
       " 'office',\n",
       " 'race',\n",
       " 'equity',\n",
       " 'journey',\n",
       " 'curious',\n",
       " 'hear',\n",
       " 'community',\n",
       " 'input',\n",
       " 'apd',\n",
       " 'commander',\n",
       " 'years',\n",
       " 'opportunity',\n",
       " 'hear',\n",
       " 'community',\n",
       " 'achieve',\n",
       " 'city',\n",
       " 'goals',\n",
       " 'lived',\n",
       " 'austin',\n",
       " 'since',\n",
       " 'saw',\n",
       " 'disparities',\n",
       " 'community',\n",
       " 'engagement',\n",
       " 'community',\n",
       " 'engagement',\n",
       " 'affordable',\n",
       " 'housing',\n",
       " 'interests',\n",
       " 'people',\n",
       " 'color',\n",
       " 'equity',\n",
       " 'office',\n",
       " 'identify',\n",
       " 'issues',\n",
       " 'share',\n",
       " 'experience',\n",
       " 'undoing',\n",
       " 'white',\n",
       " 'supremacy',\n",
       " 'austin',\n",
       " 'solutions',\n",
       " 'accountability',\n",
       " 'transparency',\n",
       " 'works',\n",
       " 'apd',\n",
       " 'perspectives',\n",
       " 'long',\n",
       " 'time',\n",
       " 'resident',\n",
       " 'police',\n",
       " 'officer',\n",
       " 'perspective',\n",
       " 'vested',\n",
       " 'interest',\n",
       " 'improving',\n",
       " 'accountability',\n",
       " 'important',\n",
       " 'issues',\n",
       " 'community',\n",
       " 'liaison',\n",
       " 'police',\n",
       " 'officer',\n",
       " 'experience',\n",
       " 'learn',\n",
       " 'new',\n",
       " 'perspective',\n",
       " 'local',\n",
       " 'issues',\n",
       " 'work',\n",
       " 'community',\n",
       " 'want',\n",
       " 'make',\n",
       " 'impact',\n",
       " 'williamson',\n",
       " 'county',\n",
       " 'listen',\n",
       " 'understand',\n",
       " 'part',\n",
       " 'solutions',\n",
       " 'impacted',\n",
       " 'listen',\n",
       " 'learn',\n",
       " 'part',\n",
       " 'conversation',\n",
       " 'years',\n",
       " 'working',\n",
       " 'hold',\n",
       " 'apd',\n",
       " 'accountable',\n",
       " 'austin',\n",
       " 'interfaith',\n",
       " 'member',\n",
       " 'organizer',\n",
       " 'part',\n",
       " 'conversation',\n",
       " 'important',\n",
       " 'conversation',\n",
       " 'excited',\n",
       " 'seeing',\n",
       " 'tangible',\n",
       " 'recommendations',\n",
       " 'east',\n",
       " 'austin',\n",
       " 'resident',\n",
       " 'years',\n",
       " 'witness',\n",
       " 'aggressive',\n",
       " 'policing',\n",
       " 'personal',\n",
       " 'experience',\n",
       " 'neighbors',\n",
       " 'black',\n",
       " 'person',\n",
       " 'living',\n",
       " 'austin',\n",
       " 'experiencing',\n",
       " 'disparities',\n",
       " 'discussed',\n",
       " 'report',\n",
       " 'personal',\n",
       " 'experience',\n",
       " 'racial',\n",
       " 'profiling',\n",
       " 'neighborhood',\n",
       " 'historically',\n",
       " 'policed',\n",
       " 'resident',\n",
       " 'east',\n",
       " 'south',\n",
       " 'austin',\n",
       " 'attorney',\n",
       " 'concerned',\n",
       " 'data',\n",
       " 'thinks',\n",
       " 'refutes',\n",
       " 'racial',\n",
       " 'profiling',\n",
       " 'disrespectful',\n",
       " 'feeling',\n",
       " 'police',\n",
       " 'different',\n",
       " 'experience',\n",
       " 'white',\n",
       " 'people',\n",
       " 'neighborhood',\n",
       " 'works',\n",
       " 'immigration',\n",
       " 'hits',\n",
       " 'close',\n",
       " 'home',\n",
       " 'concerns',\n",
       " 'impact',\n",
       " 'undocumented',\n",
       " 'people',\n",
       " 'policing',\n",
       " 'white',\n",
       " 'people',\n",
       " 'confusion',\n",
       " 'accountability',\n",
       " 'owning',\n",
       " 'disparity',\n",
       " 'concerning',\n",
       " 'police',\n",
       " 'chief',\n",
       " 'thinks',\n",
       " 'better',\n",
       " 'police',\n",
       " 'going',\n",
       " 'recommendations',\n",
       " 'police',\n",
       " 'prepared',\n",
       " 'respond',\n",
       " 'report',\n",
       " 'feeling',\n",
       " 'urgency',\n",
       " 'police',\n",
       " 'bring',\n",
       " 'lived',\n",
       " 'experiences',\n",
       " 'conversation',\n",
       " 'solutions',\n",
       " 'moving',\n",
       " 'forward',\n",
       " 'addressing',\n",
       " 'changing',\n",
       " 'parallel',\n",
       " 'approach',\n",
       " 'social',\n",
       " 'determinants',\n",
       " 'health',\n",
       " 'working',\n",
       " 'public',\n",
       " 'health',\n",
       " 'issues',\n",
       " 'students',\n",
       " 'bring',\n",
       " 'healthcare',\n",
       " 'perspective']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add your code below\n",
    "# motivation_clean = ...\n",
    "\n",
    "motivation_clean = [word.lower() for word in motivation_words \n",
    "      if word.lower() not in stopwords.words('english') \n",
    "      and word.isalpha()]\n",
    "\n",
    "motivation_clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s explore the creation of the DataFrame `top_50_df`, with two columns:\n",
    "\n",
    "- `Word`, containing the 50 most common words in `motivation_clean`\n",
    "- `Count`, containing the number of occurrences of the given word in `motivation_clean`\n",
    "\n",
    "*These values can be found in the list of tuples created when using `nltk.FreqDist()` and the `.most_common()` method.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>austin</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>police</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>community</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>experience</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resident</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>years</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>perspective</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>solutions</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>people</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>issues</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>conversation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>works</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>learn</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>social</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>work</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>equity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>apd</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>white</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>accountability</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>part</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>family</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>long</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ut</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>student</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>new</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>better</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>understand</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>share</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>public</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>office</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>hear</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>lived</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>disparities</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>engagement</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>officer</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>important</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>impact</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>listen</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>working</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>recommendations</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>east</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>policing</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>personal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>report</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>racial</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>profiling</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>neighborhood</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>thinks</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>feeling</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>bring</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word  Count\n",
       "0            austin      8\n",
       "1            police      8\n",
       "2         community      7\n",
       "3        experience      6\n",
       "4          resident      5\n",
       "5             years      4\n",
       "6       perspective      4\n",
       "7         solutions      4\n",
       "8            people      4\n",
       "9            issues      4\n",
       "10     conversation      4\n",
       "11            works      3\n",
       "12            learn      3\n",
       "13           social      3\n",
       "14             work      3\n",
       "15           equity      3\n",
       "16              apd      3\n",
       "17            white      3\n",
       "18   accountability      3\n",
       "19             part      3\n",
       "20           family      2\n",
       "21             long      2\n",
       "22               ut      2\n",
       "23          student      2\n",
       "24              new      2\n",
       "25           better      2\n",
       "26       understand      2\n",
       "27            share      2\n",
       "28           public      2\n",
       "29           office      2\n",
       "30             hear      2\n",
       "31            lived      2\n",
       "32      disparities      2\n",
       "33       engagement      2\n",
       "34          officer      2\n",
       "35        important      2\n",
       "36           impact      2\n",
       "37           listen      2\n",
       "38          working      2\n",
       "39  recommendations      2\n",
       "40             east      2\n",
       "41         policing      2\n",
       "42         personal      2\n",
       "43           report      2\n",
       "44           racial      2\n",
       "45        profiling      2\n",
       "46     neighborhood      2\n",
       "47           thinks      2\n",
       "48          feeling      2\n",
       "49            bring      2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqdist_clean = nltk.FreqDist(motivation_clean).most_common(50)\n",
    "top_50_df = pd.DataFrame(freqdist_clean, columns=['Word', 'Count'])\n",
    "top_50_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the resulting DataFrame, and whether `lemmatisation` or `stemming` might be appropriate (or some other form of grouping the words).\n",
    "\n",
    "There are no definite answers - we might think that 'officer' and 'officers' could be grouped, but perhaps these could also be grouped with 'police' and even 'apd' (Austin Police Department).\n",
    "\n",
    "We might consider using synonyms or suchlike but it may also be more appropriate to group manually, or not at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a column to `df` called `Response_Sentiment`, which contains a value given by the `.sentiment.polarity` attribute of a `TextBlob` object created from the text of each entry in the `Response` column:\n",
    "\n",
    "    The polarity score is a float within the range [-1.0, 1.0]\n",
    "    -1.0 defines a negative sentiment and 1.0 defines a positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Response_Sentiment'] = df['Response'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "df[['Response', 'Response_Sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the `.describe()` method on the Series of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Response_Sentiment'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code cell to assign the text to the variable `feedback_question`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_question = \"How do you feel about what you have learned about the Racial Profiling Report so far? \\\n",
    "What came up for you reading the data or listening to the panel?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4)** Assign to the variable `feedback`, a DataFrame containing entries in `df` where `Question` equals the `feedback_question` given above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code below\n",
    "# feedback = ...\n",
    "\n",
    "feedback = df[df['Question'] == feedback_question]\n",
    "feedback.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are three different values in the `Topic` column, with a fairly even distribution between them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback['Topic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of a DataFrame called `topic_sentiment`, using `.groupby()` on `feedback`, which shows the `mean`, `min`, and `max` `Response_Sentiment` values for each `Topic`: \n",
    "\n",
    "*You may find the pandas `.agg(['mean', 'min', 'max'])` method useful.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sentiment = feedback.groupby('Topic')['Response_Sentiment'].agg(['mean', 'min', 'max'])\n",
    "topic_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to see if there was much variation in sentiment between the five different groups which participated.\n",
    "\n",
    "Creation of a DataFrame called `group_sentiment` (adapting the same code as above) to find the same `Response_Sentiment` metrics, this time for all `Responses` in `df` and grouped by `Group`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sentiment = df.groupby('Group')['Response_Sentiment'].agg(['mean', 'min', 'max'])\n",
    "group_sentiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
