{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.6"}}, "nbformat": 4, "nbformat_minor": 2, "cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Using the Alpha Vantage API"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Once we have an API key for [Alpha Vantage](https://www.alphavantage.co/support/#api-key), let's use the `requests` library to get some data.  \n", "We can also assign the base URL and our API key to variables so that the rest of our code is easier to read and write."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import requests\n", "url = \"https://www.alphavantage.co/query\" #the section of URL which precedes the first '?'\n", "key = \"QYFZWW5LBEWDB4IA\" #change to your own API key"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Using the [API documentation](https://www.alphavantage.co/documentation/), determine which parameters are required for the TIME_SERIES_INTRADAY category, and create a dictionary containing keys for all required parameters, using `MSFT` for the symbol volue and `1min` for the interval value). Note what you would need to do if you wanted to collect all of the available data rather than just 100 data points.\n", "\n", "Next, use `requests` to `get` the data, using the dictionary you created to provide the parameters, and converting the JSON in the response to a dictionary."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["Have a look at the resulting dictionary. You'll see that the `Time Series (1min)` data that we're interested in is within it's own dictionary, nested in the original one.\n", "\n", "Convert this nested dictionary into a `Pandas DataFrame` (don't worry about keeping the metadata and other content from the original response). \n", "\n", "Use the `.transpose` method to ensure that the column containing dates is used as the index. \n", "\n", "Work out how to convert the index to `datetime` format and sort the DataFrame chronologically. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}]}